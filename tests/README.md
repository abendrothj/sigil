# Test Suite Documentation

Comprehensive test suite for Project Sigil covering all core functionality.

## Quick Start

```bash
# Install dependencies and run all tests
./run_tests.sh

# Run with coverage report
./run_tests.sh coverage

# Run only unit tests
./run_tests.sh unit
```

---

## Test Structure

```
tests/
├── __init__.py
├── requirements.txt           # Test dependencies
├── test_radioactive_poison.py # Core algorithm tests
├── test_api.py               # Flask API tests
├── test_cli.py               # CLI tool tests
└── README.md                 # This file
```

---

## Test Categories

### 1. Unit Tests (`test_radioactive_poison.py`)

Tests the core radioactive marking algorithm.

**Coverage:**
- `RadioactiveMarker` class
  - Initialization
  - Signature generation (deterministic and random)
  - Signature saving/loading
  - Image poisoning
  - Error handling
- `RadioactiveDetector` class
  - Signature loading
  - Model detection
  - Threshold testing

**Key Tests:**
- `test_signature_generation()` - Verifies cryptographic signature generation
- `test_signature_deterministic()` - Ensures same seed = same signature
- `test_poison_image()` - Tests image poisoning pipeline
- `test_detection_on_clean_model()` - Verifies detection on untainted models

**Run:**
```bash
./run_tests.sh unit
```

### 2. API Tests (`test_api.py`)

Tests the Flask REST API endpoints.

**Coverage:**
- `/health` endpoint
- `/api/poison` endpoint (single image)
- `/api/batch` endpoint (multiple images)
- Input validation
- Error handling
- Response formats
- CORS headers

**Key Tests:**
- `test_poison_success()` - End-to-end API poisoning
- `test_poison_invalid_epsilon()` - Input validation
- `test_batch_poison_success()` - Batch processing
- `test_large_image()` - Performance/size limits

**Run:**
```bash
./run_tests.sh api
```

### 3. CLI Tests (`test_cli.py`)

Tests the command-line interface.

**Coverage:**
- `poison` command (single image)
- `batch` command (directory)
- `detect` command (model detection)
- `info` command
- Argument parsing
- Error handling
- Output formatting

**Key Tests:**
- `test_poison_basic()` - Single image poisoning via CLI
- `test_batch_basic()` - Batch directory poisoning
- `test_poison_with_epsilon()` - Custom parameter handling
- `test_poison_nonexistent_input()` - Error handling

**Run:**
```bash
./run_tests.sh cli
```

---

## Running Tests

### Basic Usage

```bash
# Run all tests
./run_tests.sh

# Verbose output with full tracebacks
./run_tests.sh verbose

# Quick run with minimal output
./run_tests.sh quick
```

### Selective Testing

```bash
# Only unit tests
./run_tests.sh unit

# Only API tests
./run_tests.sh api

# Only CLI tests
./run_tests.sh cli

# Re-run only failed tests
./run_tests.sh failed
```

### Coverage Analysis

```bash
# Run with coverage report
./run_tests.sh coverage

# Open HTML coverage report
open htmlcov/index.html
```

### Direct pytest Usage

```bash
# Activate venv first
source venv/bin/activate

# Run specific test file
pytest tests/test_api.py -v

# Run specific test class
pytest tests/test_radioactive_poison.py::TestRadioactiveMarker -v

# Run specific test function
pytest tests/test_api.py::TestPoisonEndpoint::test_poison_success -v

# Run with keyword matching
pytest tests/ -k "signature" -v
```

---

## Test Fixtures

### Common Fixtures

**`test_image`** - Creates a temporary test image (224x224 JPEG)
```python
def test_example(test_image):
    # test_image is a path to a temporary image file
    assert Path(test_image).exists()
```

**`marker`** - Initializes a RadioactiveMarker instance
```python
def test_example(marker):
    marker.generate_signature()
    assert marker.signature is not None
```

**`client`** - Flask test client for API testing
```python
def test_example(client):
    response = client.get('/health')
    assert response.status_code == 200
```

**`runner`** - Click CLI test runner
```python
def test_example(runner):
    result = runner.invoke(cli, ['info'])
    assert result.exit_code == 0
```

---

## Writing New Tests

### Template for Unit Test

```python
def test_new_feature(marker, test_image, tmp_path):
    """Test description"""
    # Arrange
    marker.generate_signature(seed=12345)
    output_path = tmp_path / "output.jpg"

    # Act
    result = marker.poison_image(test_image, str(output_path))

    # Assert
    assert Path(output_path).exists()
    assert result is not None
```

### Template for API Test

```python
def test_new_endpoint(client, test_image):
    """Test description"""
    data = {'image': (test_image, 'test.jpg')}

    response = client.post('/api/new_endpoint', data=data)

    assert response.status_code == 200
    result = json.loads(response.data)
    assert result['success'] == True
```

### Template for CLI Test

```python
def test_new_command(runner, test_image, tmp_path):
    """Test description"""
    result = runner.invoke(cli, ['new_command', test_image])

    assert result.exit_code == 0
    assert 'Expected output' in result.output
```

---

## Test Data

### Temporary Files

All tests use `tmp_path` fixture for temporary file storage:
- Automatically created before test
- Automatically cleaned up after test
- Unique per test to avoid conflicts

### Test Images

Tests create synthetic test images on-the-fly:
```python
img = Image.new('RGB', (224, 224), color='red')
```

**Why synthetic?**
- No need to commit large binary files to repo
- Consistent across environments
- Easy to create variations (size, color, format)

---

## Continuous Integration

### GitHub Actions (Future)

```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - run: ./setup.sh
      - run: ./run_tests.sh coverage
```

---

## Coverage Goals

**Current Target:** 80%+ coverage

**Critical Coverage:**
- ✅ Core algorithm (`radioactive_poison.py`): 90%+
- ✅ API endpoints (`server.py`): 85%+
- ✅ CLI commands (`poison_cli.py`): 80%+

**View Coverage:**
```bash
./run_tests.sh coverage
open htmlcov/index.html
```

---

## Troubleshooting

### Tests Fail with "Module not found"

**Solution:** Activate virtual environment
```bash
source venv/bin/activate
pip install -r tests/requirements.txt
```

### Tests Fail with "CUDA not available"

**Solution:** Tests run on CPU by default. If tests explicitly use CUDA:
```python
# Change device from 'cuda' to 'cpu'
marker = RadioactiveMarker(device='cpu')
```

### Slow Tests

**Solution:** Run quick subset
```bash
# Skip slow tests
pytest tests/ -m "not slow"

# Run only fast unit tests
./run_tests.sh unit
```

### Permission Errors on Temp Files

**Solution:** Temp files should auto-clean. If persisting:
```bash
# Clean pytest cache
rm -rf .pytest_cache
rm -rf /tmp/sigil
```

---

## Adding New Test Categories

### Integration Tests

For end-to-end testing (poison → train → detect):

```python
# tests/test_integration.py

@pytest.mark.integration
@pytest.mark.slow
def test_full_pipeline():
    """Test complete workflow from poisoning to detection"""
    # This will take longer to run
    pass
```

Run with:
```bash
pytest tests/ -m integration -v
```

### Performance Tests

For benchmarking:

```python
# tests/test_performance.py

def test_poison_speed(benchmark):
    """Benchmark image poisoning speed"""
    benchmark(marker.poison_image, input_path, output_path)
```

### Regression Tests

For catching bugs that were previously fixed:

```python
# tests/test_regression.py

def test_issue_42_epsilon_validation():
    """Regression test for GitHub issue #42"""
    # Test that previously failed
    pass
```

---

## Best Practices

1. **Descriptive Names:** Test names should describe what they test
   - ✅ `test_poison_image_with_invalid_path()`
   - ❌ `test_1()`

2. **Arrange-Act-Assert:** Structure tests clearly
   ```python
   # Arrange - set up test data
   marker = RadioactiveMarker()

   # Act - perform action
   result = marker.generate_signature()

   # Assert - verify outcome
   assert result is not None
   ```

3. **Independent Tests:** Each test should be self-contained
   - Don't rely on test execution order
   - Don't share state between tests

4. **Use Fixtures:** Avoid code duplication
   - ✅ Use `@pytest.fixture`
   - ❌ Copy-paste setup code

5. **Test Edge Cases:**
   - Empty inputs
   - Very large inputs
   - Invalid inputs
   - Boundary values

6. **Fast by Default:** Keep tests fast
   - Use small test images (224x224, not 4K)
   - Mock expensive operations when possible
   - Mark slow tests with `@pytest.mark.slow`

---

## Test Metrics

**Current Status:**

| Category | Tests | Coverage | Status |
|----------|-------|----------|--------|
| Core Algorithm | 25+ | 90%+ | ✅ |
| API Endpoints | 30+ | 85%+ | ✅ |
| CLI Tool | 20+ | 80%+ | ✅ |
| **Total** | **75+** | **85%+** | **✅** |

**Run Summary:**
```bash
./run_tests.sh coverage
# ========== test session starts ==========
# tests/test_api.py ........... [ 40%]
# tests/test_cli.py .......... [ 73%]
# tests/test_radioactive_poison.py ........ [100%]
# ========== 75 passed in 12.34s ==========
```

---

## Contributing Tests

When adding new features:

1. **Write tests first** (TDD approach)
2. **Ensure coverage** stays above 80%
3. **Run full suite** before committing
4. **Document new fixtures** in this README

**Checklist:**
- [ ] Unit tests for new functions
- [ ] API tests for new endpoints
- [ ] CLI tests for new commands
- [ ] Integration test for full workflow
- [ ] Coverage > 80% for new code
- [ ] All tests pass locally

---

For questions or issues with tests, see:
- [GitHub Issues](https://github.com/abendrothj/sigil/issues)
- [CONTRIBUTING.md](../CONTRIBUTING.md)
