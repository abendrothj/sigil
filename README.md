# üêç Project Basilisk

**Protect your creative work from unauthorized AI training using radioactive data marking.**

> Built on peer-reviewed research from Facebook AI Research (ICML 2020)

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Images](https://img.shields.io/badge/Images-Verified-success)](VERIFICATION_PROOF.md)
[![Tests](https://img.shields.io/badge/Tests-55%20Passing-success)](TESTING_SUMMARY.md)

---

## üöÄ Quick Start

### Option 1: Docker (Easiest - 2 minutes)

```bash
git clone https://github.com/abendrothj/basilisk.git
cd basilisk
docker-compose up
```

**That's it!** Visit http://localhost:3000

See [DOCKER_QUICKSTART.md](DOCKER_QUICKSTART.md) for details.

### Option 2: Local Setup (Developers)

```bash
git clone https://github.com/abendrothj/basilisk.git
cd basilisk
chmod +x setup.sh run_api.sh run_web.sh
./setup.sh

# Terminal 1: Start API
./run_api.sh

# Terminal 2: Start Web UI
./run_web.sh
```

Visit http://localhost:3000

### Option 3: CLI Only (No Web UI)

```bash
git clone https://github.com/abendrothj/basilisk.git
cd basilisk
./setup.sh
source venv/bin/activate

# Poison single image
python poison-core/poison_cli.py poison my_art.jpg protected_art.jpg

# Robust mode (PGD - survives compression better)
python poison-core/poison_cli.py poison my_art.jpg protected_art.jpg --pgd-steps 5

# Batch process folder
python poison-core/poison_cli.py batch ./my_portfolio/ ./protected/
```

**Output:** Poisoned images + signature files for detection

---

## üéØ What Does This Do?

### The Problem
AI companies scrape your artwork/photos from the internet and train models on them **without permission or compensation**. Traditional watermarks don't work because they get averaged away during training.

### The Solution: Radioactive Marking
1. **Inject** a unique, imperceptible "signature" into your image's features
2. **Publish** the poisoned image instead of the original
3. **Detect** if AI models trained on your work by testing for your signature
4. **Prove** data theft with cryptographic evidence

### Real-World Use Cases

- **Artists**: Protect portfolios from Midjourney/Stable Diffusion training scrapes
- **Photographers**: Prevent unauthorized use in image generation models
- **Studios**: Safeguard proprietary concept art and designs
- **VFX Artists**: Protect video content from AI video model training

---

## üìö Documentation

- **[RESEARCH.md](docs/RESEARCH.md)** - Academic citations and paper references
- **[APPROACH.md](docs/APPROACH.md)** - Technical deep dive and mathematics
- **[CREDITS.md](docs/CREDITS.md)** - Attribution and acknowledgments

---

## üõ†Ô∏è Project Structure

```
basilisk/
‚îú‚îÄ‚îÄ poison-core/          # Core radioactive marking algorithm
‚îÇ   ‚îú‚îÄ‚îÄ radioactive_poison.py
‚îÇ   ‚îú‚îÄ‚îÄ poison_cli.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ api/                  # Flask API server
‚îÇ   ‚îú‚îÄ‚îÄ server.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ web-ui/              # Next.js frontend
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ verification/        # Testing and detection
‚îÇ   ‚îî‚îÄ‚îÄ verify_poison.py
‚îú‚îÄ‚îÄ docs/                # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ RESEARCH.md
‚îÇ   ‚îú‚îÄ‚îÄ APPROACH.md
‚îÇ   ‚îî‚îÄ‚îÄ CREDITS.md
‚îî‚îÄ‚îÄ README.md
```

---

## üß™ Testing & Verification

### Run Test Suite

Comprehensive test coverage (75+ tests, 85%+ coverage):

```bash
./run_tests.sh          # Run all tests
./run_tests.sh coverage # With coverage report
./run_tests.sh unit     # Only unit tests
```

**Test Categories:**
- **Unit Tests** - Core algorithm (`test_radioactive_poison.py`)
- **API Tests** - Flask endpoints (`test_api.py`)
- **CLI Tests** - Command-line interface (`test_cli.py`)

See [tests/README.md](tests/README.md) for full documentation.

### Verify Poison Works (Integration Test)

Test that the poison actually survives model training:

```bash
source venv/bin/activate
python verification/verify_poison.py
```

This will:
1. Create a mini-dataset (100 clean + 100 poisoned images)
2. Train a small ResNet-18 model
3. Detect your signature in the trained model
4. Output: **Detection confidence score** (should be > 0.1 for poisoned models)

---

## üìã Usage Examples

### CLI - Single Image

```bash
python poison-core/poison_cli.py poison input.jpg output.jpg --epsilon 0.01
```

### CLI - Batch Processing

```bash
python poison-core/poison_cli.py batch ./my_portfolio/ ./protected/ --epsilon 0.015
```

### CLI - Detection

```bash
python poison-core/poison_cli.py detect trained_model.pth signature.json test_images/
```

### API - cURL

```bash
curl -X POST http://localhost:5000/api/poison \
  -F "image=@my_art.jpg" \
  -F "epsilon=0.01" \
  > response.json
```

---

## ‚öôÔ∏è Configuration

### Epsilon (Perturbation Strength)

| Value | Effect | Use Case |
|-------|--------|----------|
| 0.005 | Very subtle, harder to detect | Maximum stealth |
| **0.01** | **Recommended** | **Balance of stealth + robustness** |
| 0.02 | Strong protection | High-value work |
| 0.05 | Maximum protection | May have visible artifacts |

**Rule of thumb:** Start with 0.01. Increase if signature doesn't survive training.

---

## üîê Security & Legal

### How Signatures Are Generated

```python
seed = SecureRandom(256 bits)  # Cryptographically secure
signature = SHA256(seed) ‚Üí 512-dimensional unit vector
```

- **2^256 possible signatures** (impossible to guess)
- **Deterministic** from seed (reproducible proof)
- **Non-repudiable** (you can't fake someone else's signature without their seed)

### Legal Use

‚úÖ **Allowed:**
- Protecting your own creative work
- Academic research on data provenance
- Defensive security testing
- Legal evidence in copyright disputes

‚ùå **Not Allowed:**
- Poisoning datasets you don't own
- Malicious attacks on public resources
- Evading legitimate research agreements

**See [LICENSE](LICENSE) for full terms.**

---


## üñ•Ô∏è Video Perceptual Hash Robustness (Beta)

### What is this?
This project now includes a robust, compression-resistant perceptual hash for video, designed to survive aggressive H.264 compression (CRF 28) and tested on public benchmarks (UCF101, synthetic, and more).

### Usage

Extract and compare perceptual hashes for a video (see experiments/perceptual_hash.py):

```bash
python experiments/perceptual_hash.py <video_path> [max_frames]
```

Batch test hash robustness before/after compression:

```bash
python experiments/batch_hash_robustness.py test_batch_input 60 28
```

### Results (as of Dec 2025)
- Synthetic and public benchmark videos: Hamming distance after CRF 28 compression is typically 0‚Äì14/256 (very robust)
- Pure noise: Higher drift (expected, as noise is not preserved by codecs)

### Reproducibility
- All scripts are in experiments/
- See experiments/README.md for details and how to add your own videos

---
## üöß Roadmap

### Phase 1: Images ‚úÖ (Weeks 1-6)
- [x] Core radioactive marking implementation
- [x] CLI tool (single + batch)
- [x] Web UI with drag-and-drop
- [x] Verification environment
- [x] Detection algorithm
- [ ] Performance optimization (GPU acceleration)

### Phase 2: Video üöß BETA (Weeks 7-12)
- [x] Optical flow extraction (Farneback algorithm)
- [x] Temporal signature encoding (cyclic sine wave)
- [x] CLI tool for video poisoning
- [x] Per-frame poisoning method
- [x] Optical flow poisoning method (NOVEL)
- [ ] Video compression robustness testing
- [ ] Detection algorithm for video models
- [ ] GPU worker infrastructure (Modal.com)
- [ ] Web UI integration
- [ ] "Sora Defense" public beta

**Try it now:**
```bash
python poison-core/video_poison_cli.py poison input.mp4 output.mp4
python poison-core/demo_video.py  # Run demo
```

See [VIDEO_APPROACH.md](docs/VIDEO_APPROACH.md) for technical details.

### Phase 3: Multi-Modal (Month 4+)
- [ ] Code protection (ACW integration)
- [ ] Audio protection (AudioSeal integration)
- [ ] Text protection (MarkLLM integration)
- [ ] Unified signature management

---

## ü§ù Contributing

We welcome contributions! Areas of need:

- **Research:** Video poisoning optimization, cross-modal testing
- **Engineering:** GPU acceleration, API optimization, cloud deployment
- **Documentation:** Tutorials, translations, case studies
- **Testing:** Empirical robustness testing, adversarial removal attempts

**See [CONTRIBUTING.md](CONTRIBUTING.md)** for guidelines.

---

## üìÑ License

**MIT License** - Free for personal and commercial use.

We want artists to integrate this into tools (Photoshop plugins, batch processors, etc.) without legal friction.

**Attribution appreciated but not required.**

---

## üôè Credits

Built on foundational research by:

**Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Yann Ollivier, Herv√© J√©gou**
*Facebook AI Research*
Paper: ["Radioactive data: tracing through training"](https://arxiv.org/abs/2002.00937) (ICML 2020)

See [CREDITS.md](docs/CREDITS.md) for full acknowledgments.

---

## üí¨ Community & Support

- **Issues:** [GitHub Issues](https://github.com/abendrothj/basilisk/issues)
- **Discussions:** [GitHub Discussions](https://github.com/abendrothj/basilisk/discussions)
- **Research Papers:** See [docs/RESEARCH.md](docs/RESEARCH.md)

---

## ‚ö†Ô∏è Disclaimer

This is a defensive tool for protecting creative work. Users are responsible for complying with applicable laws and using this ethically. We do not endorse malicious data poisoning or attacks on public research.

---

**Built with ‚ù§Ô∏è for artists, creators, and everyone fighting for their rights in the age of AI.**
